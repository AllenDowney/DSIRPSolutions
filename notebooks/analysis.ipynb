{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283a5bb5",
   "metadata": {},
   "source": [
    "# Analysis of Algorithms\n",
    "\n",
    "\n",
    "**Analysis of algorithms** is a branch of computer science that studies\n",
    "the performance of algorithms, especially their run time and space\n",
    "requirements. See <http://en.wikipedia.org/wiki/Analysis_of_algorithms>.\n",
    "\n",
    "The practical goal of algorithm analysis is to predict the performance\n",
    "of different algorithms in order to guide design decisions.\n",
    "\n",
    "During the 2008 United States Presidential Campaign, candidate Barack\n",
    "Obama was asked to perform an impromptu analysis when he visited Google.\n",
    "Chief executive Eric Schmidt jokingly asked him for \"the most efficient\n",
    "way to sort a million 32-bit integers.\" Obama had apparently been tipped\n",
    "off, because he quickly replied, \"I think the bubble sort would be the\n",
    "wrong way to go.\" See <http://www.youtube.com/watch?v=k4RRi_ntQc8>.\n",
    "\n",
    "This is true: bubble sort is conceptually simple but slow for large\n",
    "datasets. The answer Schmidt was probably looking for is \"radix sort\"\n",
    "(<http://en.wikipedia.org/wiki/Radix_sort>).\n",
    "\n",
    "But if you get a question like this in an interview, I think a\n",
    "    better answer is, \"The fastest way to sort a million integers is to\n",
    "    use whatever sort function is provided by the language I'm using.\n",
    "    Its performance is good enough for the vast majority of\n",
    "    applications, but if it turned out that my application was too slow,\n",
    "    I would use a profiler to see where the time was being spent. If it\n",
    "    looked like a faster sort algorithm would have a significant effect\n",
    "    on performance, then I would look around for a good implementation\n",
    "    of radix sort.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2897eab",
   "metadata": {},
   "source": [
    "The goal of algorithm analysis is to make meaningful comparisons between\n",
    "algorithms, but there are some problems:\n",
    "\n",
    "-   The relative performance of the algorithms might depend on\n",
    "    characteristics of the hardware, so one algorithm might be faster on\n",
    "    Machine A, another on Machine B. The general solution to this\n",
    "    problem is to specify a **machine model** and analyze the number of\n",
    "    steps, or operations, an algorithm requires under a given model.\n",
    "\n",
    "-   Relative performance might depend on the details of the dataset. For\n",
    "    example, some sorting algorithms run faster if the data are already\n",
    "    partially sorted; other algorithms run slower in this case. A common\n",
    "    way to avoid this problem is to analyze the **worst case** scenario.\n",
    "    It is sometimes useful to analyze average case performance, but\n",
    "    that's usually harder, and it might not be obvious what set of cases\n",
    "    to average over.\n",
    "\n",
    "-   Relative performance also depends on the size of the problem. A\n",
    "    sorting algorithm that is fast for small lists might be slow for\n",
    "    long lists. The usual solution to this problem is to express run\n",
    "    time (or number of operations) as a function of problem size, and\n",
    "    group functions into categories depending on how quickly they grow\n",
    "    as problem size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9296ee17",
   "metadata": {},
   "source": [
    "The good thing about this kind of comparison is that it lends itself to\n",
    "simple classification of algorithms. For example, if I know that the run\n",
    "time of Algorithm A tends to be proportional to the size of the input,\n",
    "$n$, and Algorithm B tends to be proportional to $n^2$, then I expect A\n",
    "to be faster than B, at least for large values of $n$.\n",
    "\n",
    "This kind of analysis comes with some caveats, but we'll get to that\n",
    "later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa65da0",
   "metadata": {},
   "source": [
    "## Order of growth\n",
    "\n",
    "Suppose you have analyzed two algorithms and expressed their run times\n",
    "in terms of the size of the input: Algorithm A takes $100n+1$ steps to\n",
    "solve a problem with size $n$; Algorithm B takes $n^2 + n + 1$ steps.\n",
    "\n",
    "The following table shows the run time of these algorithms for different\n",
    "problem sizes:\n",
    "\n",
    "```\n",
    "  -------- ------------- -------------\n",
    "     Input   Run time of   Run time of\n",
    "      size   Algorithm A   Algorithm B\n",
    "        10         1 001           111\n",
    "       100        10 001        10 101\n",
    "     1 000       100 001     1 001 001\n",
    "    10 000     1 000 001   100 010 001\n",
    "  -------- ------------- -------------\n",
    "```\n",
    "\n",
    "At $n=10$, Algorithm A looks pretty bad; it takes almost 10 times longer\n",
    "than Algorithm B. But for $n=100$ they are about the same, and for\n",
    "larger values A is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6dfa0",
   "metadata": {},
   "source": [
    "The fundamental reason is that for large values of $n$, any function\n",
    "that contains an $n^2$ term will grow faster than a function whose\n",
    "leading term is $n$. The **leading term** is the term with the highest\n",
    "exponent.\n",
    "\n",
    "For Algorithm A, the leading term has a large coefficient, 100, which is\n",
    "why B does better than A for small $n$. But regardless of the\n",
    "coefficients, there will always be some value of $n$ where\n",
    "$a n^2 > b n$, for any values of $a$ and $b$.\n",
    "\n",
    "The same argument applies to the non-leading terms. Even if the run time\n",
    "of Algorithm A were $n+1000000$, it would still be better than Algorithm\n",
    "B for sufficiently large $n$.\n",
    "\n",
    "In general, we expect an algorithm with a smaller leading term to be a\n",
    "better algorithm for large problems, but for smaller problems, there may\n",
    "be a **crossover point** where another algorithm is better. The location\n",
    "of the crossover point depends on the details of the algorithms, the\n",
    "inputs, and the hardware, so it is usually ignored for purposes of\n",
    "algorithmic analysis. But that doesn't mean you can forget about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86714057",
   "metadata": {},
   "source": [
    "If two algorithms have the same leading order term, it is hard to say\n",
    "which is better; again, the answer depends on the details. So for\n",
    "algorithmic analysis, functions with the same leading term are\n",
    "considered equivalent, even if they have different coefficients.\n",
    "\n",
    "An **order of growth** is a set of functions whose growth behavior is\n",
    "considered equivalent. For example, $2n$, $100n$ and $n+1$ belong to the\n",
    "same order of growth, which is written $O(n)$ in **Big-Oh notation** and\n",
    "often called **linear** because every function in the set grows linearly\n",
    "with $n$.\n",
    "\n",
    "All functions with the leading term $n^2$ belong to $O(n^2)$; they are\n",
    "called **quadratic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775ec55",
   "metadata": {},
   "source": [
    "The following table shows some of the orders of growth that appear most\n",
    "commonly in algorithmic analysis, in increasing order of badness.\n",
    "\n",
    "```\n",
    "  ----------------- --------------------------- --\n",
    "           Order of                        Name \n",
    "             growth                             \n",
    "             $O(1)$                    constant \n",
    "      $O(\\log_b n)$   logarithmic (for any $b$) \n",
    "             $O(n)$                      linear \n",
    "    $O(n \\log_b n)$                linearithmic \n",
    "           $O(n^2)$                   quadratic \n",
    "           $O(n^3)$                       cubic \n",
    "           $O(c^n)$   exponential (for any $c$) \n",
    "  ----------------- --------------------------- --\n",
    "```\n",
    "\n",
    "For the logarithmic terms, the base of the logarithm doesn't matter;\n",
    "changing bases is the equivalent of multiplying by a constant, which\n",
    "doesn't change the order of growth. Similarly, all exponential functions\n",
    "belong to the same order of growth regardless of the base of the\n",
    "exponent. Exponential functions grow very quickly, so exponential\n",
    "algorithms are only useful for small problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91eea2e",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Read the Wikipedia page on Big-Oh notation at\n",
    "<http://en.wikipedia.org/wiki/Big_O_notation> and answer the following\n",
    "questions:\n",
    "\n",
    "1.  What is the order of growth of $n^3 + n^2$? What about\n",
    "    $1000000 n^3 + n^2$? What about $n^3 + 1000000 n^2$?\n",
    "\n",
    "2.  What is the order of growth of $(n^2 + n) \\cdot (n + 1)$? Before you\n",
    "    start multiplying, remember that you only need the leading term.\n",
    "\n",
    "3.  If $f$ is in $O(g)$, for some unspecified function $g$, what can we\n",
    "    say about $af+b$, where $a$ and $b$ are constants?\n",
    "\n",
    "4.  If $f_1$ and $f_2$ are in $O(g)$, what can we say about $f_1 + f_2$?\n",
    "\n",
    "5.  If $f_1$ is in $O(g)$ and $f_2$ is in $O(h)$, what can we say about\n",
    "    $f_1 + f_2$?\n",
    "\n",
    "6.  If $f_1$ is in $O(g)$ and $f_2$ is $O(h)$, what can we say about\n",
    "    $f_1 \\cdot f_2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b96c57",
   "metadata": {},
   "source": [
    "Programmers who care about performance often find this kind of analysis\n",
    "hard to swallow. They have a point: sometimes the coefficients and the\n",
    "non-leading terms make a real difference. Sometimes the details of the\n",
    "hardware, the programming language, and the characteristics of the input\n",
    "make a big difference. And for small problems, order of growth is\n",
    "irrelevant.\n",
    "\n",
    "But if you keep those caveats in mind, algorithmic analysis is a useful\n",
    "tool. At least for large problems, the \"better\" algorithm is usually\n",
    "better, and sometimes it is *much* better. The difference between two\n",
    "algorithms with the same order of growth is usually a constant factor,\n",
    "but the difference between a good algorithm and a bad algorithm is\n",
    "unbounded!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b74d7",
   "metadata": {},
   "source": [
    "## Analysis of basic Python operations\n",
    "\n",
    "In Python, most arithmetic operations are constant time; multiplication\n",
    "usually takes longer than addition and subtraction, and division takes\n",
    "even longer, but these run times don't depend on the magnitude of the\n",
    "operands. Very large integers are an exception; in that case the run\n",
    "time increases with the number of digits.\n",
    "\n",
    "Indexing operations---reading or writing elements in a sequence or\n",
    "dictionary---are also constant time, regardless of the size of the data\n",
    "structure.\n",
    "\n",
    "A `for` loop that traverses a sequence or dictionary is usually linear,\n",
    "as long as all of the operations in the body of the loop are constant\n",
    "time. For example, adding up the elements of a list is linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for x in t:\n",
    "    total += x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7999f",
   "metadata": {},
   "source": [
    "The built-in function `sum` is also linear because it does the same\n",
    "thing, but it tends to be faster because it is a more efficient\n",
    "implementation; in the language of algorithmic analysis, it has a\n",
    "smaller leading coefficient.\n",
    "\n",
    "As a rule of thumb, if the body of a loop is in $O(n^a)$ then the whole\n",
    "loop is in $O(n^{a+1})$. The exception is if you can show that the loop\n",
    "exits after a constant number of iterations. If a loop runs $k$ times\n",
    "regardless of $n$, then the loop is in $O(n^a)$, even for large $k$.\n",
    "\n",
    "Multiplying by $k$ doesn't change the order of growth, but neither does\n",
    "dividing. So if the body of a loop is in $O(n^a)$ and it runs $n/k$\n",
    "times, the loop is in $O(n^{a+1})$, even for large $k$.\n",
    "\n",
    "Most string and tuple operations are linear, except indexing and ` len`,\n",
    "which are constant time. The built-in functions `min` and `max` are\n",
    "linear. The run-time of a slice operation is proportional to the length\n",
    "of the output, but independent of the size of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b57dc",
   "metadata": {},
   "source": [
    "String concatenation is linear; the run time depends on the sum of the\n",
    "lengths of the operands.\n",
    "\n",
    "All string methods are linear, but if the lengths of the strings are\n",
    "bounded by a constant---for example, operations on single\n",
    "characters---they are considered constant time. The string method `join`\n",
    "is linear; the run time depends on the total length of the strings.\n",
    "\n",
    "Most list methods are linear, but there are some exceptions:\n",
    "\n",
    "-   Adding an element to the end of a list is constant time on average;\n",
    "    when it runs out of room it occasionally gets copied to a bigger\n",
    "    location, but the total time for $n$ operations is $O(n)$, so the\n",
    "    average time for each operation is $O(1)$.\n",
    "\n",
    "-   Removing an element from the end of a list is constant time.\n",
    "\n",
    "-   Sorting is $O(n \\log n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d023f3",
   "metadata": {},
   "source": [
    "Most dictionary operations and methods are constant time, but there are\n",
    "some exceptions:\n",
    "\n",
    "-   The run time of `update` is proportional to the size of the\n",
    "    dictionary passed as a parameter, not the dictionary being updated.\n",
    "\n",
    "-   `keys`, `values` and `items` are constant time because they return\n",
    "    iterators. But if you loop through the iterators, the loop will be\n",
    "    linear.\n",
    "\n",
    "The performance of dictionaries is one of the minor miracles of computer\n",
    "science. We will see how they work soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef628c35",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Read the Wikipedia page on sorting algorithms at\n",
    "<http://en.wikipedia.org/wiki/Sorting_algorithm> and answer the\n",
    "following questions:\n",
    "\n",
    "1.  What is a \"comparison sort?\" What is the best worst-case order of\n",
    "    growth for a comparison sort? What is the best worst-case order of\n",
    "    growth for any sort algorithm?\n",
    "\n",
    "2.  What is the order of growth of bubble sort, and why does Barack\n",
    "    Obama think it is \"the wrong way to go?\"\n",
    "\n",
    "3.  What is the order of growth of radix sort? What preconditions do we\n",
    "    need to use it?\n",
    "\n",
    "4.  What is a stable sort and why might it matter in practice?\n",
    "\n",
    "5.  What is the worst sorting algorithm (that has a name)?\n",
    "\n",
    "6.  What sort algorithm does the C library use? What sort algorithm does\n",
    "    Python use? Are these algorithms stable? You might have to Google\n",
    "    around to find these answers.\n",
    "\n",
    "7.  Many of the non-comparison sorts are linear, so why does Python use\n",
    "    an $O(n \\log n)$ comparison sort?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab41205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
